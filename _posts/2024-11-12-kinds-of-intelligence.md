---
layout: post
title: Unpopular ideas on AI and epistemic humility
categories: [AI, LLM, intelligence, cogsci, preprint]
---
In this preprint Renne Pesonen and I argue that often arguments against machine intelligence are actually motivated by intuitions against **machine agency**.

In our view, the striking thing about LLMs is that they are an existence proof of structurally simple (but large!) systems that can perform many of the tasks we think require intelligence. The fact that they might do those things in a "wrong", non-human, way is beside the point: Something we thought could only be brought about by the (so far) unexplained powers of the human mind is now done by a shallow system. This should give us pause, some epistemic humility and antidote to human cognitive exceptionalism.

Preprint available [here](https://osf.io/preprints/osf/er8dg_v1) and [here](https://philarchive.org/rec/PESWYP)
<!--more-->

Here's the abstract:

Can large language models be considered intelligent? Arguments against this proposition often assume that genuine intelligence cannot exist without consciousness, understanding, or creative thinking. We discuss each of these roadblocks to machine intelligence and conclude that, in light of findings and conceptualizations in scientific research on these topics, none of them rule out the possibility of viewing current AI systems based on large language models as intelligent. We argue that consciousness is not relevant for AI, while creativity and understanding should be considered functional traits that, in principle, can be implemented in a machine. Many arguments in circulation that claim current AI systems necessarily lack these traits either rely on human exceptionalism or mistaken understanding of human intelligence. Arguments that highlight alleged flaws in current systems—such as a lack of reliability, agency, or understanding—may be important, but they often obscure the many qualitative similarities between human cognition and current AI models. We further suggest that a critical examination of high-performance AI systems can serve as a mirror through which we can reflect on our own intelligence. Many arguments against the prospects of AI may prove disconcerting for naively optimistic assessments of capacities of the human mind.